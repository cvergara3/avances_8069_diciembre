{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e081a1",
      "metadata": {
        "id": "76e081a1"
      },
      "outputs": [],
      "source": [
        "import os, re, glob, numpy as np\n",
        "from obspy.io.segy.segy import _read_segy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from pytorch_msssim import SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "from scipy.interpolate import griddata\n",
        "from scipy.spatial import QhullError\n",
        "\n",
        "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/final_model/shot_cruz_3D\"\n",
        "\n",
        "OUT_DIR  = os.path.join(\n",
        "    \"/home/pc-2/Documents/CAVE_minciencias/final_model/\",\n",
        "    \"salidas_crg_shotmask_ste_3D_ANALITICO\"\n",
        ")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "H, W = 512, 4096\n",
        "BATCH = 1\n",
        "EPOCHS = 40\n",
        "LR = 1e-4\n",
        "GLOBAL_SEED = 42\n",
        "LAMBDA_SPARSITY = 10\n",
        "SCENARIOS = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "plt.rcParams[\"figure.dpi\"] = 120\n",
        "\n",
        "\n",
        "def norm_trace_lastaxis(x):\n",
        "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
        "    return x / m\n",
        "\n",
        "def crop_to_mult8_2d(arr):\n",
        "    S, T = arr.shape[-2], arr.shape[-1]\n",
        "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
        "    return arr[..., :S8, :T8].copy()\n",
        "\n",
        "def check_divisible_by_8(h, w):\n",
        "    for v, n in [(h, \"H\"), (w, \"W\")]:\n",
        "        assert v % 8 == 0, f\"{n} debe ser múltiplo de 8\"\n",
        "\n",
        "\n",
        "def tag(fname):\n",
        "    base = os.path.basename(fname).lower()\n",
        "    m = re.search(r\"shot_sn_(\\d+)\\.(?:sgy|segy)$\", base)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "\n",
        "def load_all(base_dir):\n",
        "    pats = [\"shot_SN_*.sgy\", \"shot_SN_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    if not files:\n",
        "        raise RuntimeError(\"No encontré archivos shot_SN_*.sgy/segy\")\n",
        "\n",
        "    arrs = []\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=False)\n",
        "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
        "        arrs.append(A)\n",
        "\n",
        "    return np.stack(arrs, 0), files\n",
        "\n",
        "\n",
        "class UNet2DFull(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def blk(cin, cout):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(cin, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout),\n",
        "                nn.LeakyReLU(0.01, True),\n",
        "                nn.Conv2d(cout, cout, 3, padding=1),\n",
        "                nn.BatchNorm2d(cout),\n",
        "                nn.LeakyReLU(0.01, True)\n",
        "            )\n",
        "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2)\n",
        "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2)\n",
        "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2)\n",
        "        self.bott = blk(256,512)\n",
        "\n",
        "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
        "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
        "        self.u1 = nn.ConvTranspose2d(128,64, 2,2); self.d1 = blk(128,64)\n",
        "        self.out = nn.Conv2d(64,1,1)\n",
        "\n",
        "    def crop(self, a, b):\n",
        "        _,_,h,w = b.shape\n",
        "        _,_,H,W = a.shape\n",
        "        dh = (H-h)//2\n",
        "        dw = (W-w)//2\n",
        "        return a[:,:,dh:dh+h, dw:dw+w]\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1=self.e1(x); p1=self.p1(e1)\n",
        "        e2=self.e2(p1); p2=self.p2(e2)\n",
        "        e3=self.e3(p2); p3=self.p3(e3)\n",
        "\n",
        "        b=self.bott(p3)\n",
        "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
        "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
        "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
        "        return torch.tanh(self.out(d1))\n",
        "\n",
        "\n",
        "class BinaryShotMaskSTE(nn.Module):\n",
        "    def __init__(self, n_shots, init_keep_prob=0.9):\n",
        "        super().__init__()\n",
        "        init_keep_prob = np.clip(init_keep_prob, 1e-3, 1-1e-3)\n",
        "        init_logit = np.log(init_keep_prob/(1-init_keep_prob))\n",
        "        self.logits = nn.Parameter(torch.full((n_shots,), float(init_logit)))\n",
        "        self.n_shots = n_shots\n",
        "        self.frac_remove = 0.1\n",
        "\n",
        "    def set_frac_remove(self, frac):\n",
        "        self.frac_remove = float(frac)\n",
        "\n",
        "    def forward(self, x):\n",
        "        probs = torch.sigmoid(self.logits)\n",
        "        K = int(round(self.frac_remove * self.n_shots))\n",
        "\n",
        "        if K > 0:\n",
        "            idx_del = torch.topk(probs, K, largest=False).indices\n",
        "            hard = torch.ones_like(probs)\n",
        "            hard[idx_del] = 0.0\n",
        "        else:\n",
        "            hard = torch.ones_like(probs)\n",
        "\n",
        "        ste_mask = hard + probs - probs.detach()\n",
        "        x_masked = x * ste_mask.view(1,1,self.n_shots,1)\n",
        "        return x_masked, probs, hard\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def hard_indices_removed(self):\n",
        "        probs = torch.sigmoid(self.logits)\n",
        "        K = int(round(self.frac_remove * self.n_shots))\n",
        "        if K <= 0:\n",
        "            return np.array([], dtype=int)\n",
        "        idx_del = torch.topk(probs, K, largest=False).indices\n",
        "        return idx_del.cpu().numpy()\n",
        "\n",
        "\n",
        "def train_unet_with_shotmask(CRG_tr, pct, device):\n",
        "    S = CRG_tr.shape[1]\n",
        "    target_keep = 1 - pct/100\n",
        "\n",
        "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)\n",
        "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=BATCH, shuffle=True)\n",
        "\n",
        "    model = UNet2DFull().to(device)\n",
        "    mask_layer = BinaryShotMaskSTE(n_shots=S, init_keep_prob=target_keep).to(device)\n",
        "    mask_layer.set_frac_remove(pct/100)\n",
        "\n",
        "    opt = torch.optim.Adam(\n",
        "        [{\"params\": model.parameters(), \"lr\": LR},\n",
        "         {\"params\": mask_layer.parameters(), \"lr\": LR}]\n",
        "    )\n",
        "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
        "\n",
        "    loss_hist = []\n",
        "    model.train()\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        run = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            xb_masked, probs, hard = mask_layer(xb)\n",
        "            yp = model(xb_masked)\n",
        "\n",
        "            mask_removed = (hard == 0.0)\n",
        "            if mask_removed.any():\n",
        "                yp_sub = yp[:,:,mask_removed,:]\n",
        "                yb_sub = yb[:,:,mask_removed,:]\n",
        "                loss_rec = 1 - crit(yp_sub, yb_sub)\n",
        "            else:\n",
        "                loss_rec = torch.tensor(0., device=device)\n",
        "\n",
        "            keep_mean = torch.sigmoid(mask_layer.logits).mean()\n",
        "            loss_sp = (keep_mean - target_keep)**2\n",
        "\n",
        "            loss = loss_rec + LAMBDA_SPARSITY*loss_sp\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            run += loss.item()\n",
        "\n",
        "        loss_hist.append(run/len(loader))\n",
        "        print(f\"   Época {ep+1}/{EPOCHS} — loss={loss_hist[-1]:.5f}\")\n",
        "\n",
        "    return model, mask_layer, loss_hist\n",
        "\n",
        "\n",
        "def eval_metrics_areal(model, CRG_te, removed_idx, device, binf=2, data_range=2):\n",
        "    if len(removed_idx)==0:\n",
        "        return None\n",
        "\n",
        "    model.eval()\n",
        "    Htot, S, T = CRG_te.shape\n",
        "    R = len(removed_idx)\n",
        "\n",
        "    mse_map  = np.zeros((Htot,R), np.float32)\n",
        "    psnr_map = np.zeros((Htot,R), np.float32)\n",
        "    ssim_map = np.zeros((Htot,R), np.float32)\n",
        "    snr_map  = np.zeros((Htot,R), np.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i0 in range(0, Htot, binf):\n",
        "            i1 = min(i0+binf, Htot)\n",
        "            xb_cpu = CRG_te[i0:i1].copy()\n",
        "            xb_cpu[:, removed_idx, :] = 0\n",
        "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
        "\n",
        "            yp = model(xb).squeeze(1).cpu().numpy()\n",
        "            yt = CRG_te[i0:i1]\n",
        "\n",
        "            B = yp.shape[0]\n",
        "            for b in range(B):\n",
        "                rec_id = i0 + b\n",
        "                for j, shot_idx in enumerate(removed_idx):\n",
        "                    ypn = yp[b,shot_idx]\n",
        "                    ytn = yt[b,shot_idx]\n",
        "\n",
        "                    mse = np.mean((ytn-ypn)**2)\n",
        "                    mse_map[rec_id,j] = mse\n",
        "\n",
        "                    amp = np.max(ytn)-np.min(ytn)\n",
        "                    psnr = 20*np.log10(amp/(np.sqrt(mse+1e-12)))\n",
        "                    psnr_map[rec_id,j] = psnr\n",
        "\n",
        "                    snr = 10*np.log10((np.mean(ytn**2)+1e-12)/(mse+1e-12))\n",
        "                    snr_map[rec_id,j] = snr\n",
        "\n",
        "                    ssim_map[rec_id,j] = ssim(ytn,ypn,data_range=data_range)\n",
        "\n",
        "    per_shot = {\n",
        "        \"shot_idx\": np.array(removed_idx),\n",
        "        \"MSE\": mse_map.mean(0),\n",
        "        \"PSNR\": psnr_map.mean(0),\n",
        "        \"SSIM\": ssim_map.mean(0),\n",
        "        \"SNR\": snr_map.mean(0)\n",
        "    }\n",
        "\n",
        "    per_rec = {\n",
        "        \"rec_idx\": np.arange(Htot),\n",
        "        \"MSE\": mse_map.mean(1),\n",
        "        \"PSNR\": psnr_map.mean(1),\n",
        "        \"SSIM\": ssim_map.mean(1),\n",
        "        \"SNR\": snr_map.mean(1)\n",
        "    }\n",
        "\n",
        "    global_m = {\n",
        "        \"MSE\": mse_map.mean(),\n",
        "        \"PSNR\": psnr_map.mean(),\n",
        "        \"SSIM\": ssim_map.mean(),\n",
        "        \"SNR\": snr_map.mean()\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"mse_map\": mse_map,\n",
        "        \"psnr_map\": psnr_map,\n",
        "        \"ssim_map\": ssim_map,\n",
        "        \"snr_map\": snr_map,\n",
        "        \"per_shot\": per_shot,\n",
        "        \"per_rec\": per_rec,\n",
        "        \"global\": global_m\n",
        "    }\n",
        "\n",
        "\n",
        "def save_npz_areal(pct, areal, out_dir):\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}_areal.npz\")\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        mse_map=areal[\"mse_map\"],\n",
        "        psnr_map=areal[\"psnr_map\"],\n",
        "        ssim_map=areal[\"ssim_map\"],\n",
        "        snr_map=areal[\"snr_map\"],\n",
        "        shot_idx=areal[\"per_shot\"][\"shot_idx\"],\n",
        "        MSE_per_shot=areal[\"per_shot\"][\"MSE\"],\n",
        "        PSNR_per_shot=areal[\"per_shot\"][\"PSNR\"],\n",
        "        SSIM_per_shot=areal[\"per_shot\"][\"SSIM\"],\n",
        "        SNR_per_shot=areal[\"per_shot\"][\"SNR\"],\n",
        "        rec_idx=areal[\"per_rec\"][\"rec_idx\"],\n",
        "        MSE_per_rec=areal[\"per_rec\"][\"MSE\"],\n",
        "        PSNR_per_rec=areal[\"per_rec\"][\"PSNR\"],\n",
        "        SSIM_per_rec=areal[\"per_rec\"][\"SSIM\"],\n",
        "        SNR_per_rec=areal[\"per_rec\"][\"SNR\"],\n",
        "        MSE_global=areal[\"global\"][\"MSE\"],\n",
        "        PSNR_global=areal[\"global\"][\"PSNR\"],\n",
        "        SSIM_global=areal[\"global\"][\"SSIM\"],\n",
        "        SNR_global=areal[\"global\"][\"SNR\"]\n",
        "    )\n",
        "\n",
        "def save_csv_areal(pct, areal, out_dir):\n",
        "    ps = areal[\"per_shot\"]\n",
        "    df_shot = pd.DataFrame({\n",
        "        \"shot_idx\": ps[\"shot_idx\"],\n",
        "        \"MSE\": ps[\"MSE\"],\n",
        "        \"PSNR\": ps[\"PSNR\"],\n",
        "        \"SSIM\": ps[\"SSIM\"],\n",
        "        \"SNR\": ps[\"SNR\"]\n",
        "    })\n",
        "    df_shot.to_csv(os.path.join(out_dir, f\"metrics_per_shot_pct{pct:02d}.csv\"), index=False)\n",
        "\n",
        "    pr = areal[\"per_rec\"]\n",
        "    df_rec = pd.DataFrame({\n",
        "        \"rec_idx\": pr[\"rec_idx\"],\n",
        "        \"MSE\": pr[\"MSE\"],\n",
        "        \"PSNR\": pr[\"PSNR\"],\n",
        "        \"SSIM\": pr[\"SSIM\"],\n",
        "        \"SNR\": pr[\"SNR\"]\n",
        "    })\n",
        "    df_rec.to_csv(os.path.join(out_dir, f\"metrics_per_rec_pct{pct:02d}.csv\"), index=False)\n",
        "\n",
        "def save_npz_per_pct(pct, probs, hard, logits, removed_idx, loss_hist, metrics_dict, out_dir):\n",
        "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
        "    np.savez_compressed(\n",
        "        path,\n",
        "        probs=np.asarray(probs, dtype=np.float32),\n",
        "        hard=np.asarray(hard, dtype=np.float32),\n",
        "        logits=np.asarray(logits, dtype=np.float32),\n",
        "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
        "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
        "        MSE=metrics_dict.get(\"MSE\", None),\n",
        "        PSNR=metrics_dict.get(\"PSNR\", None),\n",
        "        SSIM=metrics_dict.get(\"SSIM\", None),\n",
        "        SNR=metrics_dict.get(\"SNR\", None),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_and_save_geometry(base_dir=BASE_DIR, out_dir=OUT_DIR):\n",
        "    pats = [\"shot_SN_*.sgy\", \"shot_SN_*.segy\"]\n",
        "    files = sorted(sum([glob.glob(os.path.join(base_dir,p)) for p in pats], []))\n",
        "    files = [f for f in files if tag(f) is not None]\n",
        "    if not files:\n",
        "        print(\"No hay SEGY para geometría\")\n",
        "        return\n",
        "\n",
        "    shot_x = []\n",
        "    shot_y = []\n",
        "    rec_x = None\n",
        "    rec_y = None\n",
        "\n",
        "    for f in files:\n",
        "        st = _read_segy(f, headonly=True)\n",
        "        tr0 = st.traces[0]\n",
        "        hdr0 = tr0.header\n",
        "\n",
        "        sx = getattr(hdr0, \"source_coordinate_x\", None)\n",
        "        sy = getattr(hdr0, \"source_coordinate_y\", None)\n",
        "        if sx is None or sy is None:\n",
        "            print(\"Faltan source_coordinate_x/y en el header\")\n",
        "            return\n",
        "\n",
        "        shot_x.append(sx)\n",
        "        shot_y.append(sy)\n",
        "\n",
        "        if rec_x is None:\n",
        "            rx = []\n",
        "            ry = []\n",
        "            for tr in st.traces:\n",
        "                h = tr.header\n",
        "                gx = getattr(h, \"group_coordinate_x\", None)\n",
        "                gy = getattr(h, \"group_coordinate_y\", None)\n",
        "                if gx is None or gy is None:\n",
        "                    print(\"Faltan group_coordinate_x/y en el header\")\n",
        "                    return\n",
        "                rx.append(gx)\n",
        "                ry.append(gy)\n",
        "            rec_x = np.array(rx,float)\n",
        "            rec_y = np.array(ry,float)\n",
        "\n",
        "    shot_x = np.array(shot_x,float)\n",
        "    shot_y = np.array(shot_y,float)\n",
        "\n",
        "    np.savez_compressed(\n",
        "        os.path.join(out_dir,\"geometry_shot_rec.npz\"),\n",
        "        shot_x=shot_x, shot_y=shot_y,\n",
        "        rec_x=rec_x, rec_y=rec_y\n",
        "    )\n",
        "    print(\">>> Geometría generada:\", len(shot_x), \"shots |\", len(rec_x),\"recs\")\n",
        "\n",
        "\n",
        "def plot_geometry_colored_by_shot_metric(pct, out_dir=OUT_DIR, metric=\"SSIM\"):\n",
        "    geom_path = os.path.join(out_dir, \"geometry_shot_rec.npz\")\n",
        "    csv_path  = os.path.join(out_dir, f\"pct_{pct:02d}\", f\"metrics_per_shot_pct{pct:02d}.csv\")\n",
        "\n",
        "    if not os.path.exists(geom_path):\n",
        "        build_and_save_geometry(BASE_DIR, out_dir)\n",
        "\n",
        "    if not os.path.exists(geom_path) or not os.path.exists(csv_path):\n",
        "        print(\"Falta geometría o CSV para el escenario\", pct)\n",
        "        return\n",
        "\n",
        "    geom = np.load(geom_path)\n",
        "    sx, sy = geom[\"shot_x\"], geom[\"shot_y\"]\n",
        "    rx, ry = geom[\"rec_x\"], geom[\"rec_y\"]\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    removed_idx = df[\"shot_idx\"].values.astype(int)\n",
        "    vals = df[metric].values.astype(float)\n",
        "\n",
        "    vmin = np.percentile(vals, 5)\n",
        "    vmax = np.percentile(vals, 95)\n",
        "    if vmin == vmax:\n",
        "        vmin = vals.min() - 1e-3\n",
        "        vmax = vals.max() + 1e-3\n",
        "\n",
        "    vals_norm = (vals - vmin) / (vmax - vmin + 1e-12)\n",
        "    vals_norm = np.clip(vals_norm, 0.0, 1.0)\n",
        "    sizes = 80 + 500 * vals_norm\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "    ax.plot(rx, ry, \"-\", color=\"lightgray\", linewidth=2, alpha=0.6, label=\"Receptores\")\n",
        "    ax.scatter(sx, sy, c=\"silver\", s=40, alpha=0.5, label=\"Shots (todos)\")\n",
        "\n",
        "    sc = ax.scatter(\n",
        "        sx[removed_idx], sy[removed_idx],\n",
        "        c=vals,\n",
        "        s=sizes,\n",
        "        cmap=\"viridis\",\n",
        "        vmin=vmin, vmax=vmax,\n",
        "        edgecolors=\"white\",\n",
        "        linewidths=1.2,\n",
        "        alpha=0.95,\n",
        "        label=f\"Shots eliminados ({metric})\"\n",
        "    )\n",
        "\n",
        "    cb = plt.colorbar(sc, ax=ax, shrink=0.8)\n",
        "    cb.set_label(metric, fontsize=12)\n",
        "\n",
        "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_title(f\"Métrica {metric} por shot — {pct}%\", fontsize=15)\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(out_dir, f\"pct_{pct:02d}\", f\"geometry_{metric}_pct{pct:02d}.png\")\n",
        "    plt.savefig(save_path, dpi=160)\n",
        "    plt.close()\n",
        "    print(\">>> Figura scatter\", metric, \"guardada en:\", save_path)\n",
        "\n",
        "\n",
        "def plot_geometry_heatmap_metric(pct, out_dir=OUT_DIR, metric=\"SSIM\",\n",
        "                                 nx=200, ny=200):\n",
        "    geom_path = os.path.join(out_dir, \"geometry_shot_rec.npz\")\n",
        "    csv_path  = os.path.join(out_dir, f\"pct_{pct:02d}\", f\"metrics_per_shot_pct{pct:02d}.csv\")\n",
        "\n",
        "    if not os.path.exists(geom_path):\n",
        "        build_and_save_geometry(BASE_DIR, out_dir)\n",
        "\n",
        "    if not os.path.exists(geom_path) or not os.path.exists(csv_path):\n",
        "        print(\"Falta geometría o CSV para heatmap en pct=\", pct)\n",
        "        return\n",
        "\n",
        "    geom = np.load(geom_path)\n",
        "    sx, sy = geom[\"shot_x\"], geom[\"shot_y\"]\n",
        "    rx, ry = geom[\"rec_x\"], geom[\"rec_y\"]\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    removed_idx = df[\"shot_idx\"].values.astype(int)\n",
        "    vals = df[metric].values.astype(float)\n",
        "\n",
        "    if len(removed_idx) == 0:\n",
        "        print(f\"No hay shots eliminados para pct={pct}\")\n",
        "        return\n",
        "\n",
        "    points = np.column_stack([sx[removed_idx], sy[removed_idx]])\n",
        "\n",
        "    xmin, xmax = sx.min(), sx.max()\n",
        "    ymin, ymax = sy.min(), sy.max()\n",
        "    dx = 0.02 * (xmax - xmin + 1e-9)\n",
        "    dy = 0.02 * (ymax - ymin + 1e-9)\n",
        "    xmin, xmax = xmin - dx, xmax + dx\n",
        "    ymin, ymax = ymin - dy, ymax + dy\n",
        "\n",
        "    grid_x, grid_y = np.meshgrid(\n",
        "        np.linspace(xmin, xmax, nx),\n",
        "        np.linspace(ymin, ymax, ny)\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        grid_vals_lin  = griddata(points, vals, (grid_x, grid_y), method=\"linear\")\n",
        "    except QhullError:\n",
        "        print(\"Advertencia: puntos casi colineales, se omite 'linear'.\")\n",
        "        grid_vals_lin = np.full_like(grid_x, np.nan, dtype=float)\n",
        "\n",
        "    grid_vals_near = griddata(points, vals, (grid_x, grid_y), method=\"nearest\")\n",
        "    grid_vals = np.where(np.isnan(grid_vals_lin), grid_vals_near, grid_vals_lin)\n",
        "\n",
        "    valid = np.isfinite(grid_vals)\n",
        "    if np.any(valid):\n",
        "        vmin = np.percentile(grid_vals[valid], 5)\n",
        "        vmax = np.percentile(grid_vals[valid], 95)\n",
        "        if vmin == vmax:\n",
        "            vmin = grid_vals[valid].min() - 1e-3\n",
        "            vmax = grid_vals[valid].max() + 1e-3\n",
        "    else:\n",
        "        vmin, vmax = vals.min(), vals.max()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "    im = ax.imshow(\n",
        "        grid_vals,\n",
        "        origin=\"lower\",\n",
        "        extent=[xmin, xmax, ymin, ymax],\n",
        "        cmap=\"viridis\",\n",
        "        vmin=vmin, vmax=vmax,\n",
        "        aspect=\"equal\"\n",
        "    )\n",
        "\n",
        "    cb = plt.colorbar(im, ax=ax, shrink=0.8)\n",
        "    cb.set_label(metric, fontsize=12)\n",
        "\n",
        "    ax.scatter(rx, ry, s=10, c=\"lightgray\", alpha=0.7, label=\"Receptores\")\n",
        "\n",
        "    ax.scatter(\n",
        "        sx[removed_idx], sy[removed_idx],\n",
        "        c=vals,\n",
        "        cmap=\"viridis\",\n",
        "        vmin=vmin, vmax=vmax,\n",
        "        edgecolors=\"black\",\n",
        "        linewidths=0.8,\n",
        "        s=60,\n",
        "        label=f\"Shots eliminados ({metric})\"\n",
        "    )\n",
        "\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    ax.set_title(f\"Heatmap espacial de {metric} — {pct}% shots eliminados\", fontsize=15)\n",
        "    ax.legend(loc=\"best\")\n",
        "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(out_dir, f\"pct_{pct:02d}\", f\"geometry_{metric}_heatmap_pct{pct:02d}.png\")\n",
        "    plt.savefig(save_path, dpi=160)\n",
        "    plt.close()\n",
        "    print(\">>> Heatmap\", metric, \"guardado en:\", save_path)\n",
        "\n",
        "\n",
        "print(\">>> Cargando SEGY…\")\n",
        "gathers_shot, file_list = load_all(BASE_DIR)\n",
        "print(\">>> Shots cargados:\", len(file_list))\n",
        "\n",
        "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W\n",
        "gathers_shot = gathers_shot[:, :H, :W]\n",
        "\n",
        "CRG_all = np.transpose(gathers_shot, (1,0,2))\n",
        "CRG_all = norm_trace_lastaxis(CRG_all)\n",
        "CRG_all = crop_to_mult8_2d(CRG_all)\n",
        "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
        "check_divisible_by_8(S8, T8)\n",
        "\n",
        "idx_rec = np.arange(CRG_all.shape[0])\n",
        "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42)\n",
        "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
        "\n",
        "print(\">>> Datos preparados. CRG_tr:\", CRG_tr.shape, \" CRG_te:\", CRG_te.shape)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dict_losses = {}\n",
        "dict_metrics_global = {}\n",
        "dict_removed_counts = {}\n",
        "\n",
        "for pct in SCENARIOS:\n",
        "    print(f\"\\n==============================\\n>> Escenario {pct}%\\n==============================\")\n",
        "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
        "    os.makedirs(sc_dir, exist_ok=True)\n",
        "\n",
        "    model, mask_layer, loss_hist = train_unet_with_shotmask(CRG_tr, pct, device)\n",
        "    dict_losses[str(pct)] = loss_hist\n",
        "\n",
        "    removed_idx = mask_layer.hard_indices_removed()\n",
        "    dict_removed_counts[str(pct)] = len(removed_idx)\n",
        "    print(\"   Shots eliminados:\", removed_idx)\n",
        "\n",
        "    areal = eval_metrics_areal(model, CRG_te, removed_idx, device)\n",
        "    save_npz_areal(pct, areal, sc_dir)\n",
        "    save_csv_areal(pct, areal, sc_dir)\n",
        "\n",
        "    metrics_global = areal[\"global\"]\n",
        "    dict_metrics_global[str(pct)] = metrics_global\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs_np = torch.sigmoid(mask_layer.logits).cpu().numpy()\n",
        "        hard_np  = np.ones_like(probs_np)\n",
        "        hard_np[removed_idx] = 0.0\n",
        "        logits_np = mask_layer.logits.detach().cpu().numpy()\n",
        "    save_npz_per_pct(pct, probs_np, hard_np, logits_np, removed_idx, loss_hist, metrics_global, sc_dir)\n",
        "\n",
        "    fig = plt.figure(figsize=(8,4))\n",
        "    plt.plot(loss_hist, '-o')\n",
        "    plt.title(f\"Pérdida (1-SSIM + λ·sparsity) — {pct}%\")\n",
        "    plt.xlabel(\"Época\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(sc_dir, \"loss_curve.png\"), dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    plot_geometry_colored_by_shot_metric(pct, OUT_DIR, metric=\"SSIM\")\n",
        "    plot_geometry_heatmap_metric(pct, OUT_DIR, metric=\"SSIM\")\n",
        "\n",
        "rows = []\n",
        "for k in sorted(dict_metrics_global.keys(), key=lambda z: int(z)):\n",
        "    m = dict_metrics_global[k]\n",
        "    rows.append({\n",
        "        \"pct_removed\": int(k),\n",
        "        \"shots_removed_count\": dict_removed_counts.get(k),\n",
        "        \"MSE\": m[\"MSE\"],\n",
        "        \"PSNR\": m[\"PSNR\"],\n",
        "        \"SSIM\": m[\"SSIM\"],\n",
        "        \"SNR\": m[\"SNR\"],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"pct_removed\")\n",
        "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_global.csv\")\n",
        "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(\"\\n>>> Listo.\")\n",
        "print(\">>> Salidas en:\", OUT_DIR)\n",
        "print(\">>> CSV global:\", csv_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "utah_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}